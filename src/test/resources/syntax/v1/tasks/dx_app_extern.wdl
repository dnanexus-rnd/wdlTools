# This file was generated by the Dx Native Interface (DxNI) tool v2.00-pre.
# These are interfaces to apps.
version 1.0

task assoc_exporter {
  input {
    String output_fname_prefix
    String chunk_by
    String db
    String tool_schema
    String table
  }

  command <<< >>>

  output {
    Array[File]+ assoc = ["dummy.txt"]
  }

  meta {
    type: "native"
    id: "app-FqV9Kb807fbB81Qg21F42gFF"
  }
}

task aws_platform_to_s3_file_transfer {
  input {
    Int worker_max
    String opt_dir
    Boolean conserve_structure
    Array[File]+ f_ids
    String target_s3
    File config_file
    String additional_upload_param
    String trans_worker_inst
  }

  command <<< >>>

  output {
    File upload_report = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F0Xzv3j0v0XzQ0GQBv0fzZVZ"
  }
}

task aws_s3_to_platform_files {
  input {
    Int worker_max
    Array[String]+ f_urls
    String target_s3
    String up_dir
    File config_file
    String trans_worker_inst
  }

  command <<< >>>

  output {
    File upload_report = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F0px8Y005x8p3Z3B8pzx3VfZ"
  }
}

task bam_to_fastq {
  input {
    File input_file
    Boolean split_pe_fastqs
    Boolean split_by_readgroups
  }

  command <<< >>>

  output {
    Array[File] output_fwd_files = []
    Array[File] output_rev_files = []
    Array[File] output_unmatched_files = []
  }

  meta {
    type: "native"
    id: "app-Bjjg95Q03KBp989yy0Fx5jbB"
  }
}

task bamtools_merge {
  input {
    Array[File]+ sorted_bams
    String advanced_options
  }

  command <<< >>>

  output {
    File sorted_bam = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-B8KZ4JQ0vFjBYypY2J1Q003B"
  }
}

task biom_to_krona {
  input {
    Array[File]+ biom_files
  }

  command <<< >>>

  output {
    Array[File]+ html_files = ["dummy.txt"]
  }

  meta {
    type: "native"
    id: "app-F259fpQ0fGx2bkKk2zPGyJF2"
  }
}

task biom_to_krona_community_test {
  input {
    Array[File]+ biom_files
  }

  command <<< >>>

  output {
    Array[File]+ html_files = ["dummy.txt"]
  }

  meta {
    type: "native"
    id: "app-F8xKpvQ0Yp71QP5yPF3qXy0F"
  }
}

task biom_to_stacked_bars {
  input {
    Array[File]+ biom_files
  }

  command <<< >>>

  output {
    Array[File]+ html_files = ["dummy.txt"]
  }

  meta {
    type: "native"
    id: "app-F24Yxv80q3gJkvyz0v192q5G"
  }
}

task bowtie2_fasta_indexer {
  input {
    File genome_fastagz
  }

  command <<< >>>

  output {
    File genomeindex_targz = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-By20Q200zZYp2BB341qgVPPQ"
  }
}

task bowtie2_fastq_read_mapper {
  input {
    String preset
    String read_group_platform_unit
    Boolean local_alignment
    String read_group_platform
    File genomeindex_targz
    String advanced_options
    String read_group_sample
    Boolean phred64
    File reads_fastqgz
    String read_group_id
    Boolean add_read_group
    String read_group_library
    File reads2_fastqgz
  }

  command <<< >>>

  output {
    File sorted_bam = "dummy.txt"
    File sorted_bai = "dummy.txt"
    Array[File]+ unmapped_reads = ["dummy.txt"]
  }

  meta {
    type: "native"
    id: "app-By21b300p519vbJZgJZkgZXZ"
  }
}

task bwa_backtrack_fastq_read_mapper {
  input {
    String read_group_platform_unit
    File genomeindex_targz
    String read_group_sample
    Boolean phred64
    File reads_fastqgz
    String advanced_aln_options
    Boolean add_read_group
    String read_group_library
    File reads2_fastqgz
    Boolean skip_casava_filtered
    String read_group_platform
    Boolean preload_index
    String advanced_samse_options
    String advanced_sampe_options
    String read_group_id
  }

  command <<< >>>

  output {
    File sorted_bam = "dummy.txt"
    File sorted_bai = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BXQy4000ffBq0KVpxvZbz5ZG"
  }
}

task bwa_fasta_indexer {
  input {
    File genome_fastagz
  }

  command <<< >>>

  output {
    File genomeindex_targz = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BXQy420098yPq6x8qxfGkf31"
  }
}

task bwa_mem_fastq_read_mapper {
  input {
    String read_group_platform_unit
    String read_group_platform
    File genomeindex_targz
    String read_group_sample
    File reads_fastqgz
    Boolean mark_as_secondary
    String read_group_id
    Boolean add_read_group
    String read_group_library
    File reads2_fastqgz
    String advanced_options
    Boolean all_alignments
  }

  command <<< >>>

  output {
    File sorted_bam = "dummy.txt"
    File sorted_bai = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BXQy44Q0Jfp7ZGQZz0Zp741F"
  }
}

task cirrus_sra_importer_app {
  input {
    String accession_number
  }

  command <<< >>>

  output {
    Array[File]+ data_files = ["dummy.txt"]
    Array[File]+ metadata_files = ["dummy.txt"]
  }

  meta {
    type: "native"
    id: "app-F3v7JK80Qv1XZ7xxJJ0fZ77f"
  }
}

task cloud_workstation {
  input {
    String max_session_length
    Array[File] fids
  }

  command <<< >>>

  meta {
    type: "native"
    id: "app-BqvpV0Q0PxgpvZ4JF5qQ0BKX"
  }
}

task cuffdiff {
  input {
    Boolean multi_read_correct
    String extra_options
    String dispersion_method
    String library_norm_method
    Float fdr
    Array[File]+ sorted_bams
    Boolean treat_as_time_series
    String library_type
    File tuxedo_resource_targz
    Boolean frag_bias_correct
  }

  command <<< >>>

  output {
    Array[File]+ results = ["dummy.txt"]
    File vennt_html = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BK3BYv00XYBG7KVqFxQQ00vJ"
  }
}

task cushaw2_fasta_indexer {
  input {
    File genome_fastagz
  }

  command <<< >>>

  output {
    File genomeindex_targz = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-FpkYJ000zxQ72VpXPjy40164"
  }
}

task cushaw2_fastq_read_mapper {
  input {
    String read_group_platform_unit
    String read_group_platform
    File genomeindex_targz
    String advanced_options
    String read_group_sample
    File reads_fastqgz
    String read_group_id
    Boolean add_read_group
    String read_group_library
    File reads2_fastqgz
  }

  command <<< >>>

  output {
    File sorted_bam = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-FpkXZv00Xz9V73B0BB4ZFQX6"
  }
}

task database_creator {
  input {
    String db_name
    String etl_config_id
    String create_mode
  }

  command <<< >>>

  output {
    String db = ""
  }

  meta {
    type: "native"
    id: "app-FqV9P3j0pQzyKjgg2166gJv3"
  }
}

task database_deleter {
  input {
    Array[String]+ db_dot_tb
    Boolean force
  }

  command <<< >>>

  meta {
    type: "native"
    id: "app-FqV9P6j0XBV2fF1321pjkBbz"
  }
}

task database_post_processor {
  input {
    File user_config
    String create_mode
    String etl_config_id
    String db
    Int bin_size
    String tgt_tb
    String insert_mode
  }

  command <<< >>>

  output {
    String database = ""
  }

  meta {
    type: "native"
    id: "app-FqV9PJ00kX0KKjgg2166gJvG"
  }
}

task dxjupyterlab {
  input {
    Int duration
    String imagename
    File snapshot
  }

  command <<< >>>

  meta {
    type: "native"
    id: "app-FpZQY8Q99pbv8Vkv5Y2yqJ7P"
  }
}

task dxjupyterlab_spark_cluster {
  input {
    Int duration
    String imagename
    File snapshot
    String feature
  }

  command <<< >>>

  meta {
    type: "native"
    id: "app-Fq1K3pj0V5GjJv4ZBfVXVq4q"
  }
}

task dxwdl_clone_asset {
  input {
    String url
    String folder
    String filename
  }

  command <<< >>>

  output {
    File ofile = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-Ff9jFZ00Q3x8YjyY6zkbPXkX"
  }
}

task dxwdl_copy_file {
  input {
    String url
    String folder
    String filename
  }

  command <<< >>>

  output {
    File ofile = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-Ff9k9gQ0Yzpj5k6b703y0Xy9"
  }
}

task fastq_to_fasta_bth {
  input {
    Array[File]+ fastqgz
  }

  command <<< >>>

  output {
    Array[File]+ fastagz = ["dummy.txt"]
  }

  meta {
    type: "native"
    id: "app-F417Gj00gXffYv7B63PG1vq2"
  }
}

task fastqc {
  input {
    String format
    Int kmer_size
    File adapters_txt
    Boolean nogroup
    File limits_txt
    File reads
    File contaminants_txt
    String extra_options
  }

  command <<< >>>

  output {
    File report_html = "dummy.txt"
    File stats_txt = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BZ9bfkQ0fg1y9V5qq89y2851"
  }
}

task fc_hpc_daligner {
  input {
    Int length_cutoff
    String daligner_version
    Int max_n_read
    Int max_files_per_merge
    Int min_cov_aln
    Int edge_tolerance
    File dazzler_db
    Int num_block_comparisons_per_daligner_call
    String file_prefix
    Boolean rerun_consensus
    Int min_len_aln
    Int min_cov
    Int num_threads_per_daligner_job
    String daligner_arguments
    Boolean generate_consensus_fastas
    Float min_idt
    Boolean create_plan_script_only
    String daligner_instance_type
    String rerun_job_id
    Int sync_time
    Int trim_size
    Int num_blocks
    Boolean trim
    String lasort_instance_type
    Boolean skip_contained
  }

  command <<< >>>

  output {
    Array[File] output_files = []
    Array[File] consensus_fastas = []
    File daligner_plan_script = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F019Z9j0G6bx2K2p3Gzqqv12"
  }
}

task file_concatenator {
  input {
    Array[File]+ files
    String output_filename
  }

  command <<< >>>

  output {
    File file = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BZ9ZQzQ02VP5gpkP54b96pYY"
  }
}

task flexbar_fastq_read_trimmer {
  input {
    Int trim_left
    String advanced_options
    Int min_length
    Boolean phred64
    File reads_fastqgz
    Int trim_right
    Int max_uncalled
    Int trim_quality_threshold
    File reads2_fastqgz
  }

  command <<< >>>

  output {
    File trimmed_reads_fastqgz = "dummy.txt"
    File trimmed_reads2_fastqgz = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-Fpk0vxQ9gy35jp5gB8gkVQ7x"
  }
}

task freebayes {
  input {
    Boolean normalize_variants
    File genome_fastagz
    String output_prefix
    Array[File]+ sorted_bams
    String advanced_options
    File targets_bed
    Boolean parallelized
    Boolean standard_filters
  }

  command <<< >>>

  output {
    File variants_vcfgz = "dummy.txt"
    File variants_tbi = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BZ9ZV580PX9gvKVqF0b77x2v"
  }
}

task gatk_lite_unified_genotyper {
  input {
    File genome_fastagz
    Array[File]+ sorted_bams
    File dbsnp_vcfgz
    String advanced_options
    String glm
  }

  command <<< >>>

  output {
    File variants_vcfgz = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BFQ3VZQ06BPQgg4FG8k003VJ"
  }
}

task hisat2_index {
  input {
    File snp_file
    File variants_vcf
    File exon_file
    String cmd_line_args
    String index_prefix
    File ss_file
    File haplotype_file
    File transcr_annotation_gtf
    String snp_vcf_type
    File ref_input_fasta
    Int num_cores
  }

  command <<< >>>

  output {
    File genome_index_targz = "dummy.txt"
    Array[File] hisat_tab_files = []
  }

  meta {
    type: "native"
    id: "app-F2fxj680Pj7x3G232Zv9VVzF"
  }
}

task hisat2_mapper {
  input {
    File genome_index
    String out_prefix
    String cmd_line_args
    Int num_cores
    Array[File] reads_rev_fa
    Array[File]+ reads_fwd_fa
  }

  command <<< >>>

  output {
    File sorted_mappings_bam = "dummy.txt"
    File index_bai = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F2fxjJj0528f99qy2b26G1x9"
  }
}

task hpc_repmask {
  input {
    Int local_alignment_size
    Int band_width
    Int num_consecutive_blocks
    Int cov_threashhold
    Int max_mem
    File dazzler_db
    Float avg_correlation
    Int max_kmer
    Int num_threads_per_daligner_job
    Boolean use_mask
    Int kmer_size
    Int trace_point_freq
    Int min_covered_bases
    Int num_daligner_blocks_per_job
    String advanced_options
  }

  command <<< >>>

  output {
    File output_db = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F019ZJj0Pz6VBGkJYxV0yzQb"
  }
}

task hpc_tanmask {
  input {
    Int local_alignment_size
    Int kmer_size
    Int band_width
    String advanced_options
    File dazzler_db
    Float avg_correlation
    Int trace_point_freq
    Int min_covered_bases
  }

  command <<< >>>

  output {
    File output_db = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F019ZVQ0G9gXBkY964zzPgj7"
  }
}

task lofreq {
  input {
    File sorted_bam
    File genome_fastagz
    String advanced_options
  }

  command <<< >>>

  output {
    File variants_vcfgz = "dummy.txt"
    File variants_tbi = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BZBvPQ80b1j77kkgp89xPqVf"
  }
}

task lofreq_somatic {
  input {
    File genome_fastagz
    File tumor_bam
    File dbsnp
    String advanced_options
    File target_bed
    File normal_bam
  }

  command <<< >>>

  output {
    File snvs_vcfgz = "dummy.txt"
    File snvs_tbi = "dummy.txt"
    File indels_vcfgz = "dummy.txt"
    File indels_tbi = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BZBvPyj05p1gj382j89bVbB7"
  }
}

task megahit {
  input {
    Array[File] reads_interlaced
    String k_list
    Array[File] reads_rev_pe
    Boolean save_compressed
    Int k_max
    String presets
    Int min_contig
    Array[File] reads_fwd_pe
    Int k_min
    Int threads
    Int min_count
    Float memory
    Int k_step
    Array[File] reads_unpaired
  }

  command <<< >>>

  output {
    File contigs = "dummy.txt"
    File output_compressed = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F29xk1j0kv165Y3y63j34bFg"
  }
}

task native_hello {
  input {
    String who
  }

  command <<< >>>

  output {
    String greeting = ""
  }

  meta {
    type: "native"
    id: "app-FGybxy00k03JX74548Vp63JV"
  }
}

task picard_collect_multiple_metrics {
  input {
    File sorted_bam
    File fasta_index
    String extra_options
  }

  command <<< >>>

  output {
    Array[File]+ stats = ["dummy.txt"]
  }

  meta {
    type: "native"
    id: "app-F08X2gj0362422b0k1Z4F89J"
  }
}

task pindel_0_2_4t {
  input {
    Boolean vcf_gatk_compatible
    Boolean bam_not_produced_by_bwa
    Int num_threads_per_instance
    Boolean report_inversions
    Boolean report_breakpoints
    File reference_fasta
    Boolean report_only_close_mapped_reads
    String sequence_platform
    String export_vcf_advanced_options
    Array[File] bam_index_files
    Boolean report_close_mapped_reads
    Int insert_size
    Boolean input_is_pindel
    Boolean report_duplications
    Array[File]+ mappings_files
    File bam_config_file
    Int num_instances
    String pindel_command_line
    Boolean assume_sorted
    String output_prefix
    Boolean report_long_insertions
    Boolean report_read_pair
    File breakdancer_calls_file
    String chromosome
    Boolean export_vcf
    File fasta_index
  }

  command <<< >>>

  output {
    File short_inserts = "dummy.txt"
    File breakpoints = "dummy.txt"
    File tandem_duplications = "dummy.txt"
    File close_mapped_reads = "dummy.txt"
    File inversions = "dummy.txt"
    Array[File] sortedbam_and_index_files = []
    File vcf = "dummy.txt"
    File large_inserts = "dummy.txt"
    File deletions = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-B80g69j00F9yzjZG85gQ1Ky9"
  }
}

task pindel_vcf_converter {
  input {
    File reference
    String vcf_output_name
    String pindel2vcf_advanced_options
    String reference_name
    String reference_date
    Array[File]+ pindel_output_files
    Boolean export_gatk_compatible
  }

  command <<< >>>

  output {
    File vcf = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-B80YbYQ0kbvF8V2gpj9Q0kzg"
  }
}

task plato_single_variant_tis {
  input {
    Array[String] correction
    File fam_file
    String plato_analysis_string
    String association_type
    Float maf_threshold
    File input_categorical_covariate_txt
    File input_samples_txt
    String outcome
    Int case_threshold
    String missingness
    Boolean mem
    File input_continuous_covariate_txt
    File phenotypes_tsv
    String regression
    File bim_file
    File bed_file
    String output_filename
    File input_markers_txt
    Int split_phenotype
    String covariates
  }

  command <<< >>>

  output {
    Array[File]+ output_files = ["dummy.txt"]
    File output_clean = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-FqV9VGQ02xJ5Qxx74VXQPxv9"
  }
}

task plink_single_variant {
  input {
    Float marker_hwe
    Boolean include_cc_stats
    Boolean output_full_results
    String interaction_term
    Float marker_missing
    File phenotypes_tsv
    File bim_file
    File bed_file
    File covariates_tsv
    Float marker_maf_min
    Float marker_maf_max
    Int marker_count_min
    Int marker_count_max
    Float confidence_interval
    File fam_file
    String assoc_model
  }

  command <<< >>>

  output {
    File output_log = "dummy.txt"
    File output_clean = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-FqV9Q8j01X75Qxx74VXQPxqV"
  }
}

task bamtools_merge {
  input {
    Array[File]+ sorted_bams
    String advanced_options
  }

  command <<< >>>

  output {
    File sorted_bam = "dummy.txt"
    File sorted_bai = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-FBVKPz00yvjfgGBqP9b4X4qK"
  }
}

task samtools_index {
  input {
    File sorted_bam
  }

  command <<< >>>

  output {
    File index_bai = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-B6vV0Fj0Kqb9V2P3g5BQ00pQ"
  }
}

task samtools_sort {
  input {
    File mappings_bam
    Boolean by_name
  }

  command <<< >>>

  output {
    File sorted_bam = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BBKQqf80qy1ZpzFk2Zx004QF"
  }
}

task samtools_variant_caller {
  input {
    Array[File]+ sorted_bams
    File genome_fastagz
    String advanced_st_options
    String advanced_bt_options
  }

  command <<< >>>

  output {
    File variants_vcfgz = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-FpkY1980VYk7ZQy36VvGz7fk"
  }
}

task sentieon_dnaseq_bam {
  input {
    Boolean ignore_decoy
    String mark_or_remove_duplicate
    File genome_fastagz
    Int bam_compression_level
    String haplotyper_algo_options
    String gvcftyper_algo_options
    Boolean run_deduplicate
    Array[File] targets_bed
    File mappings_sorted_bam
    File gatk_resource_bundle
    String output_refined_bam_to_output
  }

  command <<< >>>

  output {
    File variants_gvcf = "dummy.txt"
    File mappings_recaled_bam = "dummy.txt"
    File variants_gvcftbi = "dummy.txt"
    File mappings_recaled_bai = "dummy.txt"
    File recal_table = "dummy.txt"
    File mappings_realigned_bai = "dummy.txt"
    File mappings_realigned_bam = "dummy.txt"
    File variants_vcftbi = "dummy.txt"
    File variants_vcf = "dummy.txt"
    File dedup_metrics = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F4GXzjQ0f5p4Qfy8FBggXKG0"
  }
}

task sentieon_dnaseq_fq {
  input {
    Boolean ignore_decoy
    String mark_or_remove_duplicate
    File genome_fastagz
    String extra_bwa_options
    Array[File] reads2_fastqgzs
    File genomeindex_targz
    File rg_info_csv
    String haplotyper_algo_options
    String gvcftyper_algo_options
    Array[File]+ reads_fastqgzs
    String output_refined_bam_to_output
    String read_group_platform
    Int bam_compression_level
    Array[File] targets_bed
    String sample
    Boolean mark_as_secondary
    File gatk_resource_bundle
  }

  command <<< >>>

  output {
    File mappings_deduped_bai = "dummy.txt"
    File mappings_deduped_bam = "dummy.txt"
    File variants_gvcf = "dummy.txt"
    File variants_gvcftbi = "dummy.txt"
    File mappings_recaled_bai = "dummy.txt"
    File recal_table = "dummy.txt"
    File mappings_realigned_bai = "dummy.txt"
    File mappings_realigned_bam = "dummy.txt"
    File variants_vcftbi = "dummy.txt"
    File variants_vcf = "dummy.txt"
    File mappings_recaled_bam = "dummy.txt"
    Array[File]+ metrics = ["dummy.txt"]
  }

  meta {
    type: "native"
    id: "app-F4GXv5003k5VK8Y6FF072Fy8"
  }
}

task sentieon_tnseq_bam {
  input {
    Boolean ignore_decoy
    String mark_or_remove_duplicate
    Boolean tnsnv_algo
    Int bam_compression_level
    File normal_mappings_sorted_bam
    File tumor_mappings_sorted_bam
    String tnhaplotyper_algo_options
    Boolean run_deduplicate
    Array[File] targets_bed
    Boolean tnhaplotyper_algo
    File gatk_resource_bundle
    String output_refined_bam_to_output
    String tnsnv_algo_options
    File genome_fastagz
  }

  command <<< >>>

  output {
    File normal_mappings_recaled_bam = "dummy.txt"
    File tumor_mappings_realigned_bam = "dummy.txt"
    File tumor_mappings_recaled_bam = "dummy.txt"
    File variants_tnsnv_vcf = "dummy.txt"
    File normal_dedup_metrics = "dummy.txt"
    File tumor_recal_table = "dummy.txt"
    File tumor_mappings_recaled_bai = "dummy.txt"
    File callstats_txt = "dummy.txt"
    File normal_mappings_recaled_bai = "dummy.txt"
    File tn_mappings_corealigned_bam = "dummy.txt"
    File normal_mappings_realigned_bam = "dummy.txt"
    File variants_tnsnv_vcftbi = "dummy.txt"
    File variants_tnhaplotyper_vcftbi = "dummy.txt"
    File variants_tnhaplotyper_vcf = "dummy.txt"
    File normal_recal_table = "dummy.txt"
    File tn_mappings_corealigned_bai = "dummy.txt"
    File tumor_mappings_realigned_bai = "dummy.txt"
    File tumor_dedup_metrics = "dummy.txt"
    File normal_mappings_realigned_bai = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F4GY0F00v8qY7Kz2Jb3ypq3Y"
  }
}

task sentieon_tnseq_fq {
  input {
    Boolean ignore_decoy
    String extra_bwa_options
    File genomeindex_targz
    File rg_info_csv
    String normal_sample
    String tnhaplotyper_algo_options
    Array[File] targets_bed
    String tumor_sample
    Boolean tnhaplotyper_algo
    String output_refined_bam_to_output
    String mark_or_remove_duplicate
    Array[File] normal_reads2_fastqgzs
    String tnsnv_algo_options
    Array[File] tumor_reads2_fastqgzs
    File genome_fastagz
    Boolean tnsnv_algo
    Array[File]+ normal_reads_fastqgzs
    Array[File]+ tumor_reads_fastqgzs
    String read_group_platform
    Int bam_compression_level
    Boolean mark_as_secondary
    File gatk_resource_bundle
  }

  command <<< >>>

  output {
    File tumor_mappings_realigned_bam = "dummy.txt"
    Array[File]+ tumor_metrics = ["dummy.txt"]
    File tumor_mappings_recaled_bam = "dummy.txt"
    File variants_tnsnv_vcf = "dummy.txt"
    File tumor_recal_table = "dummy.txt"
    File tumor_mappings_recaled_bai = "dummy.txt"
    File normal_mappings_deduped_bam = "dummy.txt"
    File callstats_txt = "dummy.txt"
    File normal_mappings_deduped_bai = "dummy.txt"
    File normal_mappings_recaled_bai = "dummy.txt"
    File normal_mappings_realigned_bai = "dummy.txt"
    File tn_mappings_corealigned_bam = "dummy.txt"
    File normal_mappings_realigned_bam = "dummy.txt"
    Array[File]+ normal_metrics = ["dummy.txt"]
    File normal_mappings_recaled_bam = "dummy.txt"
    File variants_tnsnv_vcftbi = "dummy.txt"
    File variants_tnhaplotyper_vcftbi = "dummy.txt"
    File variants_tnhaplotyper_vcf = "dummy.txt"
    File tumor_mappings_deduped_bai = "dummy.txt"
    File normal_recal_table = "dummy.txt"
    File tn_mappings_corealigned_bai = "dummy.txt"
    File tumor_mappings_realigned_bai = "dummy.txt"
    File tumor_mappings_deduped_bam = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F4GXy100v6q5GJF2FFxYjZY5"
  }
}

task sjcp_cache_app {
  command <<< >>>

  meta {
    type: "native"
    id: "app-F3P8vyQ9Y8bvzZy5BX432yPf"
  }
}

task spades {
  input {
    File forward_reads
    File reverse_reads
  }

  command <<< >>>

  output {
    File assembly = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-B6Ybj8ggYjBpb19y6QYQ00vk"
  }
}

task spark_sql_runner {
  input {
    String executor_memory
    Int executor_cores
    Boolean export
    String log_level
    File substitutions
    String driver_memory
    File sqlfile
    Boolean collect_logs
    File user_config
    File export_options
  }

  command <<< >>>

  output {
    Array[File] output_files = []
  }

  meta {
    type: "native"
    id: "app-FqV9QFQ0JYGKJJvX213B4YF9"
  }
}

task sra_importer {
  input {
    String accession_number
  }

  command <<< >>>

  output {
    File file_metadata = "dummy.txt"
    Array[File]+ fastq_gzs = ["dummy.txt"]
    String string_metadata = ""
  }

  meta {
    type: "native"
    id: "app-F2P4x000V51f1f2vGX6gX9FG"
  }
}

task sra_importer_app {
  input {
    String accession_number
  }

  command <<< >>>

  output {
    Array[String]+ files = [""]
  }

  meta {
    type: "native"
    id: "app-F2Pz8yQ0bxBf1f2vGX6gq6Qx"
  }
}

task star_generate_genome_index {
  input {
    File sjdbGTFfile
    File input_fasta
    Int sjdbOverhang
    Int genomeSAsparseD
    String cmd_line_args
    Int genomeSAindexNbases
    Int genomeSuffixLengthMax
    Int genomeChrBinNbits
    String output_prefix
    File sjdbFileChrStartEnd
  }

  command <<< >>>

  output {
    File output_genome = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-Bvvz8gQ0bGY1XjfBg59bzVzf"
  }
}

task star_generate_genome_index_ {
  input {
    String output_prefix
    File transcr_annotation_gtf
    Int length_overhang
    Int genome_chr_bin_nbits
    Int length_sa_index
    Int genome_suffix_length_max
    Int sa_sparsity
    String cmd_line_args
    File ref_input_fasta
    File splice_junctions_tsv
  }

  command <<< >>>

  output {
    File genome_index_targz = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F2G9g3006Q2xyZKx5yQpQp4b"
  }
}

task star_generate_genome_index_edit {
  input {
    String output_prefix
    File transcr_annotation_gtf
    Int length_overhang
    Int genome_chr_bin_nbits
    Int length_sa_index
    Int genome_suffix_length_max
    Int sa_sparsity
    String cmd_line_args
    File ref_input_fasta
    File splice_junctions_tsv
  }

  command <<< >>>

  output {
    File genome_index_targz = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F1fkPq0059fFgJK033X5gjjq"
  }
}

task star_mapping {
  input {
    Boolean map_to_transcriptome
    Array[File]+ fwd_reads
    String cmd_line_args
    Array[File] rev_reads
    String output_prefix
    File genome_index
  }

  command <<< >>>

  output {
    File genome_bam = "dummy.txt"
    File log_file = "dummy.txt"
    File splice_junctions = "dummy.txt"
    File transcriptome_bam = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BvvzGjj0p7jVz39xj99bGk2Q"
  }
}

task star_mapping_ {
  input {
    String output_genome_opt
    Array[File] splice_junction_tabfiles
    Boolean two_pass_basic
    Int first_pass_max_reads
    String cmd_line_args
    String output_prefix
    File genome_index
    Boolean map_to_transcriptome
    File transcr_annotation_gtf
    Array[File] reads_rev_fa
    Array[File]+ reads_fwd_fa
  }

  command <<< >>>

  output {
    File splice_junctions = "dummy.txt"
    File transcriptome_bam = "dummy.txt"
    File map_stat_log = "dummy.txt"
    Array[File] other_outputs = []
    File genome_bam = "dummy.txt"
    File regen_genome_indx = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-F2G9Yy005xZJJgvv5xkp3bKF"
  }
}

task synthetic_pvcf_generator {
  input {
    Int num_individuals_per_partition
    Int num_partitions
    Int num_partitions_per_chr
    File tbi
    File vcf
  }

  command <<< >>>

  output {
    Array[File]+ pvcf = ["dummy.txt"]
  }

  meta {
    type: "native"
    id: "app-FqV9QPQ0bgyyKjgg2166gJvk"
  }
}

task tgex_exporter {
  input {
    String sample_sequence_machine_id
    String sample_serial_number
    String subject_gender
    String sample_notes
    String subject_dob
    String sample_sequence_date
    String sample_target
    String sample_source
    String sample_enrichment_kit_id
    File vcf_file
    String subject_id
    String subject_name
    String sample_type
    String customer_account_key
    String sample_taken_date
  }

  command <<< >>>

  output {
    String url_link = ""
  }

  meta {
    type: "native"
    id: "app-F02V0PQ0f4791bGxkkB15pf1"
  }
}

task tmap_bam_read_mapper {
  input {
    File reads_bam
    File genomeindex_targz
    Boolean mark_as_bidirectional
    String advanced_options
  }

  command <<< >>>

  output {
    File sorted_bam = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BFG5f5005Kx5zgk0ZJ5Q08Pk"
  }
}

task tmap_fasta_indexer {
  input {
    File genome_fastagz
  }

  command <<< >>>

  output {
    File genomeindex_targz = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BBYbk5803Yg6Y8XB34GQ028K"
  }
}

task tophat_known_genes {
  input {
    String preset
    Int mate_inner_dist
    String extra_options
    Array[File] reads2_fastqgz
    Boolean no_novel_juncs
    Boolean transcriptome_only
    String sample_name
    Boolean phred64
    String library_type
    File tuxedo_resource_targz
    Int replicate_index
    Array[File]+ reads_fastqgz
  }

  command <<< >>>

  output {
    File sorted_bam = "dummy.txt"
    File summary_txt = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BQfF0k80v5bJ20f39j9Q4QX0"
  }
}

task torrentsuite_variant_caller {
  input {
    File genome_fastagz
    File hotspot_bed
    File targets_bed
    Boolean trim_reads
    File sorted_bam
    String custom_ia_options
    String custom_tvc_options
    String settings
    String custom_hotspot_options
  }

  command <<< >>>

  output {
    File variants_vcfgz = "dummy.txt"
    File variants_tbi = "dummy.txt"
    File variants_tsv = "dummy.txt"
    File alleles_tsv = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BP7Kkp80K37JpzfJ54BQ000K"
  }
}

task tuxedo_resource_builder {
  input {
    File genomeindex_targz
    File genes_gtfgz
  }

  command <<< >>>

  output {
    File tuxedo_resource_targz = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BQfF12801kKzFjZZ6Gy008Y2"
  }
}

task vcf_loader {
  input {
    String create_mode
    String spark_executor_memory
    Boolean verbose
    Boolean exclude_refdata
    File vcf_manifest
    String cluster_master_log_level
    String run_mode
    String recovery_key
    Boolean calculate_worst_effects
    Boolean calculate_locus_frequencies
    String snpeff_human_genome
    File dbsnp_bundle
    Boolean snpeff
    String etl_spec_id
    File gnomad_bundle
    Int num_init_partitions
    Int num_anno_step_partitions
    String recovery_mode
    String cluster_workers_log_level
    Float spark_memory_fraction
    Boolean is_sample_partitioned
    Boolean snpeff_opt_no_downstream
    Boolean snpsift
    String insert_mode
    String database_name
    Int spark_sql_shuffle_partitions
    Boolean snpsift_gnomad
    Boolean snpeff_opt_no_upstream
    Int spark_executor_cores
  }

  command <<< >>>

  output {
    String database = ""
  }

  meta {
    type: "native"
    id: "app-FqV9Qy80xyJKKjgg2166gJx5"
  }
}

task vcf_to_plink_apollo {
  input {
    String sel_args
    String prefix
    File fam_in
    Int marker_count_max
    File variants_vcfgz
    Float marker_maf_min
    Boolean strict
    Float marker_hwe
    Float marker_maf_max
    Int marker_count_min
    Boolean biallelic
    Float marker_missing
    Boolean snp_only
  }

  command <<< >>>

  output {
    File bed_out = "dummy.txt"
    File misssamples_out = "dummy.txt"
    File bim_out = "dummy.txt"
    File fam_out = "dummy.txt"
    File log_out = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-FqV9V7803Xz495v64Q3JKPY9"
  }
}

task velvet {
  input {
    Int coverage_mask
    Boolean scaffolding
    String exp_cov
    File long
    Int min_pair_count
    Int long_mult_cutoff
    Int ins_length2_sd
    Int max_branch_length
    Int min_contig_lgth
    String long_cov_cutoff
    Int max_gap_count
    Boolean read_trkg
    File shortPaired2
    Boolean amos_file
    File shortPaired
    File short2
    File longPaired
    Int ins_length2
    Boolean very_clean
    File short
    Boolean mergeShortPaired
    Boolean exportFiltered
    String max_divergence
    Boolean clean
    Boolean mergeShortPaired2
    Int hash_length
    String cov_cutoff
    Boolean mergeLongPaired2
    Boolean conserveLong
    Float paired_exp_fraction
    Boolean alignments
    String max_coverage
    Boolean shortMatePaired
    Boolean unused_reads
    Int ins_length_long
    Int ins_length
  }

  command <<< >>>

  output {
    File assembly = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BJ7F4z80yJbz1BqG35X0077K"
  }
}

task vendor_human_exome_gatk_lite_pipeline {
  input {
    String advanced_pr_options
    Boolean novel_indel_realignment
    String advanced_ir_options
    String advanced_br_options
    String advanced_ug_options
    String advanced_rtc_options
    String glm
    String vendor_exome
    File sorted_bam
    String advanced_md_options
  }

  command <<< >>>

  output {
    File variants_vcfgz = "dummy.txt"
    File variants_tbi = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-BP3QZvQ0bf3jB9xVxjg0065f"
  }
}

task vendor_human_exome_selection_metrics {
  input {
    File sorted_bam
    String vendor_exome
    String validation_stringency
    String advanced_options
  }

  command <<< >>>

  output {
    File hsmetrics_tsv = "dummy.txt"
    File pertarget_coverage_tsv = "dummy.txt"
  }

  meta {
    type: "native"
    id: "app-B8P84K00PZ1zFvbqv57Q05Bk"
  }
}